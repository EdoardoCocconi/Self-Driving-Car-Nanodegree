{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Finding Lane Lines on the Road** \n",
    "***\n",
    "The aim of this project is to identify lane lines in a video of highway driving. The video results can be whatched directly at the bottom of this Jupyter Notebook. Line detection is performed first on individual images and then on video footage by repeating the same process on each frame.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# importing some useful packages\n",
    "%load_ext nb_black\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read in an Image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reading in an image\n",
    "image = mpimg.imread(\"test_images/solidWhiteRight.jpg\")\n",
    "\n",
    "# printing out some stats and plotting\n",
    "print(\"This image is:\", type(image), \"with dimensions:\", image.shape)\n",
    "plt.imshow(\n",
    "    image\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "\n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    `vertices` should be a numpy array of integer points.\n",
    "    \"\"\"\n",
    "    # defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)\n",
    "\n",
    "    # defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "\n",
    "    # filling pixels inside the polygon defined by \"vertices\" with the fill color\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "    # returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=5):\n",
    "\n",
    "    rm = []\n",
    "    rcx = []\n",
    "    rcy = []\n",
    "    weightr = []\n",
    "    ybottomr = img.shape[0]\n",
    "    ytopr = img.shape[0]\n",
    "\n",
    "    lm = []\n",
    "    lcx = []\n",
    "    lcy = []\n",
    "    weightl = []\n",
    "    ybottoml = img.shape[0]\n",
    "    ytopl = img.shape[0]\n",
    "\n",
    "    smoothing_parameter = 15\n",
    "\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            center = ((x2 + x1) / 2, (y2 + y1) / 2)\n",
    "            distance = math.sqrt(((x2 - x1) ** 2) + ((y2 - y1) ** 2))\n",
    "            if 0.82 > abs(slope) > 0.49:\n",
    "                if np.sign(slope) == 1:\n",
    "                    lm.append(slope)\n",
    "                    lcx.append(center[0])\n",
    "                    lcy.append(center[1])\n",
    "                    weightl.append(distance)\n",
    "                    if y1 < ytopl:\n",
    "                        ytopl = y1\n",
    "                    if y2 < ytopl:\n",
    "                        ytopl = y2\n",
    "                else:\n",
    "                    rm.append(slope)\n",
    "                    rcx.append(center[0])\n",
    "                    rcy.append(center[1])\n",
    "                    weightr.append(distance)\n",
    "                    if y1 < ytopr:\n",
    "                        ytopr = y1\n",
    "                    if y2 < ytopr:\n",
    "                        ytopr = y2\n",
    "\n",
    "    if len(rcx) != 0:\n",
    "        zr = np.polyfit(rcx, rcy, 1, w=weightr)\n",
    "        fr = np.poly1d(zr)\n",
    "        if -0.8 < fr.coef[0] < -0.49:\n",
    "            ytopr_history.append(ytopr)\n",
    "            if len(ytopr_history) > smoothing_parameter:\n",
    "                ytopr_history.pop(0)\n",
    "            ytopr = sum(ytopr_history) / len(ytopr_history)\n",
    "            yr = [ybottomr, ytopr]\n",
    "            xr = [(fr - yr[0]).roots, (fr - yr[1]).roots]\n",
    "            cv2.line(\n",
    "                img, (int(xr[0]), yr[0]), (int(xr[1]), int(yr[1])), color, thickness,\n",
    "            )\n",
    "\n",
    "    if len(lcx) != 0:\n",
    "        zl = np.polyfit(lcx, lcy, 1, w=weightl)\n",
    "        fl = np.poly1d(zl)\n",
    "        if 0.8 > fl.coef[0] > 0.49:\n",
    "            ytopl_history.append(ytopl)\n",
    "            if len(ytopl_history) > smoothing_parameter:\n",
    "                ytopl_history.pop(0)\n",
    "            ytopl = sum(ytopl_history) / len(ytopl_history)\n",
    "            yl = [ybottoml, ytopl]\n",
    "            xl = [(fl - yl[0]).roots, (fl - yl[1]).roots]\n",
    "            cv2.line(\n",
    "                img, (int(xl[0]), yl[0]), (int(xl[1]), int(yl[1])), color, thickness,\n",
    "            )\n",
    "\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "\n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(\n",
    "        img,\n",
    "        rho,\n",
    "        theta,\n",
    "        threshold,\n",
    "        np.array([]),\n",
    "        minLineLength=min_line_len,\n",
    "        maxLineGap=max_line_gap,\n",
    "    )\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1.0, γ=0.0):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "\n",
    "    `initial_img` should be the image before any processing.\n",
    "\n",
    "    The result image is computed as follows:\n",
    "\n",
    "    initial_img * α + img * β + γ\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "global ytopr_history\n",
    "ytopr_history = []\n",
    "global ytopl_history\n",
    "ytopl_history = []\n",
    "\n",
    "files = os.listdir(\"test_images/\")\n",
    "\n",
    "for file in files:\n",
    "    ytopr_history.clear()\n",
    "    ytopl_history.clear()\n",
    "    if file[0:6] != \"output\":\n",
    "        image_img = mpimg.imread(\"test_images/\" + file)\n",
    "        image_gray = grayscale(image_img)\n",
    "        image_gray = gaussian_blur(image_gray, 3)\n",
    "        image_edges = canny(image_gray, 60, 180)\n",
    "        image_imshape = image_img.shape\n",
    "\n",
    "        image_vertices = np.array(\n",
    "            [\n",
    "                [\n",
    "                    (0.51 * image_imshape[1], image_imshape[0] * 0.58),\n",
    "                    (0.49 * image_imshape[1], image_imshape[0] * 0.58),\n",
    "                    (0, image_imshape[0]),\n",
    "                    (image_imshape[1], image_imshape[0]),\n",
    "                ]\n",
    "            ],\n",
    "            dtype=np.int32,\n",
    "        )\n",
    "\n",
    "        image_target = region_of_interest(image_edges, image_vertices)\n",
    "        image_lines = hough_lines(image_target, 1, np.pi / 180, 35, 5, 2)\n",
    "        image_result = weighted_img(image_lines, image_img, α=0.8, β=1.0)\n",
    "        plt.imshow(image_result, cmap=\"gray\")\n",
    "        r, g, b = cv2.split(image_result)\n",
    "        image_result = cv2.merge((b, g, r))\n",
    "        cv2.imwrite(\"test_images/output\" + file, image_result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test on Videos\n",
    "\n",
    "We can test our solution on two provided videos:\n",
    "\n",
    "`solidWhiteRight.mp4`\n",
    "\n",
    "`solidYellowLeft.mp4`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    frame_gray = grayscale(frame)\n",
    "    frame_gray = gaussian_blur(frame_gray, 3)\n",
    "    frame_edges = canny(frame_gray, 60, 180)\n",
    "    frame_imshape = frame.shape\n",
    "\n",
    "    frame_vertices = np.array(\n",
    "        [\n",
    "            [\n",
    "                (0.51 * frame_imshape[1], frame_imshape[0] * 0.58),\n",
    "                (0.49 * frame_imshape[1], frame_imshape[0] * 0.58),\n",
    "                (0, frame_imshape[0]),\n",
    "                (frame_imshape[1], frame_imshape[0]),\n",
    "            ]\n",
    "        ],\n",
    "        dtype=np.int32,\n",
    "    )\n",
    "\n",
    "    frame_target = region_of_interest(frame_edges, frame_vertices)\n",
    "    frame_lines = hough_lines(frame_target, 1, np.pi / 180, 35, 5, 2)\n",
    "    frame_result = weighted_img(frame_lines, frame, α=0.8, β=1.0)\n",
    "    return frame_result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try the one with the solid white lane on the right first."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "white_output = \"test_videos_output/solidWhiteRight.mp4\"\n",
    "ytopr_history.clear()\n",
    "ytopl_history.clear()\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_frame)  # NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Play the video inline, or if you prefer find the video in your filesystem (should be in the same directory) and play it in your video player of choice."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HTML(\n",
    "    \"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\n",
    "        white_output\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now for the one with the solid yellow lane on the left. This one's more tricky!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "yellow_output = \"test_videos_output/solidYellowLeft.mp4\"\n",
    "ytopr_history.clear()\n",
    "ytopl_history.clear()\n",
    "clip2 = VideoFileClip(\"test_videos/solidYellowLeft.mp4\")\n",
    "yellow_clip = clip2.fl_image(process_frame)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HTML(\n",
    "    \"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\n",
    "        yellow_output\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optional Challenge\n",
    "\n",
    "In the optional challenge, the lane finding pipeline is tested in conditions it was not designed for. Curves and changes in lighting condition require a more advanced pipeline that will be developed in Project 2 - Advanced Lane Finding. The output can be seen below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "challenge_output = \"test_videos_output/challenge.mp4\"\n",
    "ytopr_history.clear()\n",
    "ytopl_history.clear()\n",
    "clip3 = VideoFileClip(\"test_videos/challenge.mp4\")\n",
    "challenge_clip = clip3.fl_image(process_frame)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HTML(\n",
    "    \"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\n",
    "        challenge_output\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}